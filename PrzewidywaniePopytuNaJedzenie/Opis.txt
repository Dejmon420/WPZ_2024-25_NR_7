Importowanie bibliotek:
-numpy i pandas do pracy z danymi.
-RandomForestRegressor i GradientBoostingRegressor jako modele regresji.
-train_test_split z sklearn.model_selection do podziału danych.
-mean_squared_error do oceny błędu modelu.

Ładowanie danych: Wczytywane są cztery zbiory danych:
-data – zbiór treningowy zawierający informacje o zapotrzebowaniu na jedzenie.
-center – informacje o centrum realizacji.
-meal – informacje o posiłkach.
-test – zbiór testowy, który służy do prognozowania zapotrzebowania.

Łączenie danych:
-Funkcja pd.concat łączy zbiór treningowy i testowy, co pozwala na jednolite przetwarzanie cech.
-Następnie merge łączy dane data z danymi center i meal na podstawie kluczy center_id oraz meal_id.

Inżynieria cech:
-discount_amount – różnica między ceną podstawową a ceną końcową (czyli kwota zniżki).
-discount_percent – procentowa wartość zniżki.
-discount_y/n – wskaźnik 1, jeśli zniżka jest dostępna, i 0, jeśli nie ma zniżki.

Podział danych na zbiór treningowy i testowy:
Dane są podzielone według numerów tygodnia. Tygodnie 1-145 stanowią zbiór treningowy, a tygodnie 146-155 są traktowane jako testowy.

Selekcja cech:
-X_train zawiera wszystkie kolumny poza num_orders (liczba zamówień, czyli zmienna docelowa), id oraz week.
-y_train zawiera wartości docelowe num_orders dla treningu.
-X_test zawiera cechy bez num_orders, id i week, na podstawie których przewidujemy zapotrzebowanie.

RandomForestRegressor:
-RandomForestRegressor to model lasu losowego z liczbą drzew (n_estimators) ustawioną na 100 i stałą losową (random_state) dla powtarzalności wyników.
-.fit(X_train, y_train) trenuje model na danych treningowych.
-.predict(X_test) przewiduje liczbę zamówień na danych testowych.

GradientBoostingRegressor:
-GradientBoostingRegressor to model bazujący na gradientowym wzmocnieniu, również z liczbą estymatorów ustawioną na 100 i stałą losową dla powtarzalności.
-.fit(X_train, y_train) – trenuje model na tych samych danych.
-.predict(X_test) – generuje przewidywania dla zbioru testowego.

Ocena błędu przy użyciu RMSE (Root Mean Squared Error):
-mean_squared_error(y_train, rf_train_predictions, squared=False) oblicza pierwiastek średniego błędu kwadratowego dla modelu RandomForest.
-mean_squared_error(y_train, gb_train_predictions, squared=False) wykonuje to samo dla modelu GradientBoosting.
-Wyniki RMSE wskazują, który model lepiej dopasowuje się do danych.

Wizualizacja wyników:
-Porównanie RMSE – wykres słupkowy z błędami RMSE dla obu modeli.
-Porównanie wartości rzeczywistych i przewidywanych – wykres liniowy dla próbek z testu, pokazujący, jak przewidywania obu modeli wypadają względem rzeczywistych wartości. Dla czytelność wykresu przedstawiono tylko wyniki 50 pierwszych próbek.



Pseudokod:
# Importowanie niezbędnych bibliotek
Wczytaj numpy jako np
Wczytaj pandas jako pd
Wczytaj modele: RandomForestRegressor, GradientBoostingRegressor z sklearn.ensemble
Wczytaj funkcje train_test_split oraz mean_squared_error z sklearn
Wczytaj matplotlib.pyplot jako plt

# Ładowanie danych
Wczytaj plik 'train.csv' jako train_data
Wczytaj plik 'fulfilment_center_info.csv' jako center_info
Wczytaj plik 'meal_info.csv' jako meal_info
Wczytaj plik 'test_QoiMO9B.csv' jako test_data

# Łączenie danych
Połącz train_data i test_data wzdłuż osi wierszy
Połącz train_data i center_info na kluczu 'center_id' (łączenie typu lewego)
Połącz train_data i meal_info na kluczu 'meal_id' (łączenie typu lewego)

# Inżynieria cech
Dla każdej obserwacji w train_data oblicz:
    'discount_amount' jako różnica między 'base_price' a 'checkout_price'
    'discount_percent' jako procent zniżki: (base_price - checkout_price) / base_price * 100
    'discount_y/n' jako 1, jeśli base_price > checkout_price, inaczej 0

# Podział na zbiór treningowy i testowy
Podziel train_data na:
    train – tylko tygodnie od 1 do 145
    test – tylko tygodnie od 146 do 155

# Selekcja cech i etykiety
Utwórz X_train, zawierający wszystkie kolumny z train poza 'num_orders', 'id', 'week'
Utwórz y_train, zawierający kolumnę 'num_orders' z train
Utwórz X_test, zawierający wszystkie kolumny z test poza 'num_orders', 'id', 'week'

# Trenowanie modelu RandomForestRegressor
Zainicjalizuj model RandomForestRegressor z 100 estymatorami i random_state = 42
Dopasuj model do x_train i y_train
Wykonaj prognozy na x_test i zapisz jako rf_predictions

# Trenowanie modelu GradientBoostingRegressor
Zainicjalizuj model GradientBoostingRegressor z 100 estymatorami i random_state = 42
Dopasuj model do x_train i y_train
Wykonaj prognozy na x_test i zapisz jako gb_predictions

# Ocena modeli na zbiorze treningowym
Wykonaj prognozy modelu RandomForest na x_train i zapisz jako rf_train_predictions
Wykonaj prognozy modelu GradientBoosting na x_train i zapisz jako gb_train_predictions
Oblicz RMSE dla modelu RandomForest jako mean_squared_error(y_train, rf_train_predictions, squared=False)
Oblicz RMSE dla modelu GradientBoosting jako mean_squared_error(y_train, gb_train_predictions, squared=False)

# Wizualizacja wyników
Ustaw tytuł wykresu jako "Porównanie modeli: Random Forest i Gradient Boosting"
Wykres słupkowy RMSE dla każdego modelu:
    - Dla RandomForest wyświetl jako słupek z etykietą "RandomForest RMSE"
    - Dla GradientBoosting wyświetl jako słupek z etykietą "GradientBoosting RMSE"
Ustaw etykiety osi y jako "Błąd RMSE"

# Wizualizacja porównania wartości rzeczywistych i przewidywanych dla obu modeli
Utwórz wykres liniowy wartości rzeczywistych i przewidywanych dla x_test
    - Wartości rzeczywiste: y_test (jeśli dostępne, inaczej użyj 'num_orders' z x_test)
    - Przewidywania RandomForest: rf_predictions, dodaj etykietę "RandomForest Predictions"
    - Przewidywania GradientBoosting: gb_predictions, dodaj etykietę "GradientBoosting Predictions"
Ustaw etykiety osi x i y oraz tytuł wykresu jako "Porównanie wartości rzeczywistych i przewidywanych"

# Wyświetl wykresy
Wyświetl wszystkie wykresy
